{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "# import numpy as np\n",
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import matplotlib.dates as mdates\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leer datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar el directorio raíz del proyecto a sys.path\n",
    "from Dict.dict_df import dict_df\n",
    "project_root = os.getcwd()\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Importar el diccionario desde Dict/dict_df.py\n",
    "from Dict.dict_df import dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la ruta del archivo CSV\n",
    "csv_path_df = os.path.join('Data', '.ipynb_checkpoints', 'df.csv')\n",
    "\n",
    "# Leer el CSV usando el diccionario de tipos\n",
    "df = pd.read_csv(csv_path_df, dtype=dict_df, parse_dates=['Begin_Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4849 entries, 0 to 4848\n",
      "Data columns (total 20 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   Customer_ID        4849 non-null   object        \n",
      " 1   Begin_Date         4849 non-null   datetime64[ns]\n",
      " 2   End_Date           4849 non-null   object        \n",
      " 3   Type               4849 non-null   object        \n",
      " 4   Paperless_Billing  4849 non-null   object        \n",
      " 5   Payment_Method     4849 non-null   object        \n",
      " 6   Monthly_Charges    4849 non-null   float64       \n",
      " 7   Total_Charges      4849 non-null   float64       \n",
      " 8   Gender             4849 non-null   object        \n",
      " 9   Senior_Citizen     4849 non-null   int64         \n",
      " 10  Partner            4849 non-null   object        \n",
      " 11  Dependents         4849 non-null   object        \n",
      " 12  Multiple_Lines     4849 non-null   object        \n",
      " 13  Internet_Service   4849 non-null   object        \n",
      " 14  Online_Security    4849 non-null   object        \n",
      " 15  Online_Backup      4849 non-null   object        \n",
      " 16  Device_Protection  4849 non-null   object        \n",
      " 17  Tech_Support       4849 non-null   object        \n",
      " 18  Streaming_TV       4849 non-null   object        \n",
      " 19  Streaming_Movies   4849 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(2), int64(1), object(16)\n",
      "memory usage: 757.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv('Data\\.ipynb_checkpoints\\df.csv', parse_dates=['Begin_Date'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End_Date\n",
      "0    4439\n",
      "1     410\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['End_Date'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminación de la columna Customer_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez realizada la unión de los datasets en un DataFrame __df__ ya se puede eliminar la columna __Customer_ID__ para proseguir con el preprocesamiento de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4849 entries, 0 to 4848\n",
      "Data columns (total 20 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   Customer_ID        4849 non-null   object        \n",
      " 1   Begin_Date         4849 non-null   datetime64[ns]\n",
      " 2   End_Date           4849 non-null   int8          \n",
      " 3   Type               4849 non-null   object        \n",
      " 4   Paperless_Billing  4849 non-null   object        \n",
      " 5   Payment_Method     4849 non-null   object        \n",
      " 6   Monthly_Charges    4849 non-null   float64       \n",
      " 7   Total_Charges      4849 non-null   float64       \n",
      " 8   Gender             4849 non-null   object        \n",
      " 9   Senior_Citizen     4849 non-null   int64         \n",
      " 10  Partner            4849 non-null   object        \n",
      " 11  Dependents         4849 non-null   object        \n",
      " 12  Multiple_Lines     4849 non-null   object        \n",
      " 13  Internet_Service   4849 non-null   object        \n",
      " 14  Online_Security    4849 non-null   object        \n",
      " 15  Online_Backup      4849 non-null   object        \n",
      " 16  Device_Protection  4849 non-null   object        \n",
      " 17  Tech_Support       4849 non-null   object        \n",
      " 18  Streaming_TV       4849 non-null   object        \n",
      " 19  Streaming_Movies   4849 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(2), int64(1), int8(1), object(15)\n",
      "memory usage: 724.6+ KB\n"
     ]
    }
   ],
   "source": [
    "## Convertir la columna 'End_Date' a int\n",
    "df['End_Date'] = pd.to_numeric(df['End_Date'], downcast='integer')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4849 entries, 0 to 4848\n",
      "Data columns (total 19 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   Begin_Date         4849 non-null   datetime64[ns]\n",
      " 1   End_Date           4849 non-null   int8          \n",
      " 2   Type               4849 non-null   object        \n",
      " 3   Paperless_Billing  4849 non-null   object        \n",
      " 4   Payment_Method     4849 non-null   object        \n",
      " 5   Monthly_Charges    4849 non-null   float64       \n",
      " 6   Total_Charges      4849 non-null   float64       \n",
      " 7   Gender             4849 non-null   object        \n",
      " 8   Senior_Citizen     4849 non-null   int64         \n",
      " 9   Partner            4849 non-null   object        \n",
      " 10  Dependents         4849 non-null   object        \n",
      " 11  Multiple_Lines     4849 non-null   object        \n",
      " 12  Internet_Service   4849 non-null   object        \n",
      " 13  Online_Security    4849 non-null   object        \n",
      " 14  Online_Backup      4849 non-null   object        \n",
      " 15  Device_Protection  4849 non-null   object        \n",
      " 16  Tech_Support       4849 non-null   object        \n",
      " 17  Streaming_TV       4849 non-null   object        \n",
      " 18  Streaming_Movies   4849 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(2), int64(1), int8(1), object(14)\n",
      "memory usage: 686.8+ KB\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Begin_Date</th>\n",
       "      <th>End_Date</th>\n",
       "      <th>Type</th>\n",
       "      <th>Paperless_Billing</th>\n",
       "      <th>Payment_Method</th>\n",
       "      <th>Monthly_Charges</th>\n",
       "      <th>Total_Charges</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Senior_Citizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Multiple_Lines</th>\n",
       "      <th>Internet_Service</th>\n",
       "      <th>Online_Security</th>\n",
       "      <th>Online_Backup</th>\n",
       "      <th>Device_Protection</th>\n",
       "      <th>Tech_Support</th>\n",
       "      <th>Streaming_TV</th>\n",
       "      <th>Streaming_Movies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>0</td>\n",
       "      <td>one year</td>\n",
       "      <td>yes</td>\n",
       "      <td>mailed check</td>\n",
       "      <td>65.6</td>\n",
       "      <td>593.30</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>dsl</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>0</td>\n",
       "      <td>month-to-month</td>\n",
       "      <td>no</td>\n",
       "      <td>mailed check</td>\n",
       "      <td>59.9</td>\n",
       "      <td>542.40</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>dsl</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>1</td>\n",
       "      <td>month-to-month</td>\n",
       "      <td>yes</td>\n",
       "      <td>electronic check</td>\n",
       "      <td>73.9</td>\n",
       "      <td>280.85</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>fiber optic</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>1</td>\n",
       "      <td>month-to-month</td>\n",
       "      <td>yes</td>\n",
       "      <td>electronic check</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1237.85</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>fiber optic</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>0</td>\n",
       "      <td>month-to-month</td>\n",
       "      <td>yes</td>\n",
       "      <td>credit card</td>\n",
       "      <td>69.4</td>\n",
       "      <td>571.45</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>dsl</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Begin_Date  End_Date            Type Paperless_Billing    Payment_Method  \\\n",
       "0 2019-05-01         0        one year               yes      mailed check   \n",
       "1 2019-05-01         0  month-to-month                no      mailed check   \n",
       "2 2019-09-01         1  month-to-month               yes  electronic check   \n",
       "3 2018-12-01         1  month-to-month               yes  electronic check   \n",
       "4 2019-05-01         0  month-to-month               yes       credit card   \n",
       "\n",
       "   Monthly_Charges  Total_Charges  Gender  Senior_Citizen Partner Dependents  \\\n",
       "0             65.6         593.30  female               0     yes        yes   \n",
       "1             59.9         542.40    male               0      no         no   \n",
       "2             73.9         280.85    male               0      no         no   \n",
       "3             98.0        1237.85    male               1     yes         no   \n",
       "4             69.4         571.45  female               0      no        yes   \n",
       "\n",
       "  Multiple_Lines Internet_Service Online_Security Online_Backup  \\\n",
       "0             no              dsl              no           yes   \n",
       "1            yes              dsl              no            no   \n",
       "2             no      fiber optic              no            no   \n",
       "3             no      fiber optic              no           yes   \n",
       "4             no              dsl              no            no   \n",
       "\n",
       "  Device_Protection Tech_Support Streaming_TV Streaming_Movies  \n",
       "0                no          yes          yes               no  \n",
       "1                no           no           no              yes  \n",
       "2               yes           no           no               no  \n",
       "3               yes           no          yes              yes  \n",
       "4                no          yes          yes              yes  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.drop('Customer_ID', axis=1)\n",
    "df.info()\n",
    "print()\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción de información de la columna __Begin_Date__ y eliminación posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4849 entries, 0 to 4848\n",
      "Data columns (total 23 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   Begin_Date         4849 non-null   datetime64[ns]\n",
      " 1   End_Date           4849 non-null   int8          \n",
      " 2   Type               4849 non-null   object        \n",
      " 3   Paperless_Billing  4849 non-null   object        \n",
      " 4   Payment_Method     4849 non-null   object        \n",
      " 5   Monthly_Charges    4849 non-null   float64       \n",
      " 6   Total_Charges      4849 non-null   float64       \n",
      " 7   Gender             4849 non-null   object        \n",
      " 8   Senior_Citizen     4849 non-null   int64         \n",
      " 9   Partner            4849 non-null   object        \n",
      " 10  Dependents         4849 non-null   object        \n",
      " 11  Multiple_Lines     4849 non-null   object        \n",
      " 12  Internet_Service   4849 non-null   object        \n",
      " 13  Online_Security    4849 non-null   object        \n",
      " 14  Online_Backup      4849 non-null   object        \n",
      " 15  Device_Protection  4849 non-null   object        \n",
      " 16  Tech_Support       4849 non-null   object        \n",
      " 17  Streaming_TV       4849 non-null   object        \n",
      " 18  Streaming_Movies   4849 non-null   object        \n",
      " 19  Year               4849 non-null   int32         \n",
      " 20  Month              4849 non-null   int32         \n",
      " 21  Day                4849 non-null   int32         \n",
      " 22  dow                4849 non-null   int32         \n",
      "dtypes: datetime64[ns](1), float64(2), int32(4), int64(1), int8(1), object(14)\n",
      "memory usage: 762.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df['Year'] = df['Begin_Date'].dt.year\n",
    "df['Month'] = df['Begin_Date'].dt.month\n",
    "df['Day'] = df['Begin_Date'].dt.day\n",
    "df['dow'] = df['Begin_Date'].dt.dayofweek\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4849 entries, 0 to 4848\n",
      "Data columns (total 22 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   End_Date           4849 non-null   int8   \n",
      " 1   Type               4849 non-null   object \n",
      " 2   Paperless_Billing  4849 non-null   object \n",
      " 3   Payment_Method     4849 non-null   object \n",
      " 4   Monthly_Charges    4849 non-null   float64\n",
      " 5   Total_Charges      4849 non-null   float64\n",
      " 6   Gender             4849 non-null   object \n",
      " 7   Senior_Citizen     4849 non-null   int64  \n",
      " 8   Partner            4849 non-null   object \n",
      " 9   Dependents         4849 non-null   object \n",
      " 10  Multiple_Lines     4849 non-null   object \n",
      " 11  Internet_Service   4849 non-null   object \n",
      " 12  Online_Security    4849 non-null   object \n",
      " 13  Online_Backup      4849 non-null   object \n",
      " 14  Device_Protection  4849 non-null   object \n",
      " 15  Tech_Support       4849 non-null   object \n",
      " 16  Streaming_TV       4849 non-null   object \n",
      " 17  Streaming_Movies   4849 non-null   object \n",
      " 18  Year               4849 non-null   int32  \n",
      " 19  Month              4849 non-null   int32  \n",
      " 20  Day                4849 non-null   int32  \n",
      " 21  dow                4849 non-null   int32  \n",
      "dtypes: float64(2), int32(4), int64(1), int8(1), object(14)\n",
      "memory usage: 724.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df.drop('Begin_Date', axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de features y target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['End_Date']\n",
    "features = df.drop('End_Date', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_path = os.path.join('Data', '.ipynb_checkpoints', 'target.csv')\n",
    "features_path = os.path.join('Data', '.ipynb_checkpoints', 'features.csv')\n",
    "\n",
    "target.to_csv('Data/.ipynb_checkpoints/target.csv', index=False)\n",
    "features.to_csv('Data/.ipynb_checkpoints/features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear función para crear diccionario y guardarlo como script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict(data, name):\n",
    "    '''\n",
    "    Función para crear un diccionario donde las claves son las columnas de un DataFrame\n",
    "    y los valores son los tipos de datos (dtypes) de cada columna. Si es una Series, \n",
    "    se usará su nombre como clave y su tipo de dato como valor.\n",
    "    \n",
    "    Args:\n",
    "    - data: DataFrame o Series de pandas\n",
    "    - name: Nombre que se usará como base para el diccionario (ej. \"df\")\n",
    "    \n",
    "    Returns:\n",
    "    - Un diccionario Python\n",
    "    '''\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        # Crear el diccionario con las columnas como claves y los tipos de datos como valores\n",
    "        column_dict = {col: str(dtype)\n",
    "                       for col, dtype in zip(data.columns, data.dtypes)}\n",
    "    elif isinstance(data, pd.Series):\n",
    "        # Crear el diccionario con el nombre de la Series como clave y su tipo de dato como valor\n",
    "        column_dict = {data.name: str(data.dtype)}\n",
    "    else:\n",
    "        raise TypeError(\n",
    "            \"El objeto data debe ser un DataFrame o una Series de pandas.\")\n",
    "\n",
    "    # Retornar el diccionario\n",
    "    return {f'dict_{name}': column_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End_Date\n"
     ]
    }
   ],
   "source": [
    "print(target.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dict_target': {'End_Date': 'int8'}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_dict(target, 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict_as_py(column_dict, name, folder='Dict'):\n",
    "    \"\"\"\n",
    "    Guarda un diccionario como un archivo .py en la carpeta especificada.\n",
    "    \n",
    "    Args:\n",
    "    - column_dict: El diccionario que se desea guardar.\n",
    "    - name: El nombre del archivo (sin extensión .py).\n",
    "    - folder: La carpeta donde se guardará el archivo (por defecto: 'Dict').\n",
    "    \"\"\"\n",
    "    # Asegurarse de que la carpeta existe\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Crear la ruta completa del archivo\n",
    "    file_path = os.path.join(folder, f'dict_{name}.py')\n",
    "\n",
    "    # Escribir el diccionario en el archivo como código Python\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(f\"# Diccionario generado automáticamente para {name}\\n\")\n",
    "        file.write(f\"dict_df = {column_dict}\\n\")\n",
    "\n",
    "    print(f\"Diccionario guardado exitosamente en: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diccionario guardado exitosamente en: Dict\\dict_dict_target.py\n"
     ]
    }
   ],
   "source": [
    "save_dict_as_py('dict_target', 'dict_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict_as_py(data, name, folder='Dict'):\n",
    "    \"\"\"\n",
    "    Guarda un diccionario como un archivo .py en la carpeta especificada.\n",
    "    \n",
    "    Args:\n",
    "    - column_dict: El diccionario que se desea guardar.\n",
    "    - name: El nombre del archivo (sin extensión .py).\n",
    "    - folder: La carpeta donde se guardará el archivo (por defecto: 'Dict').\n",
    "    \"\"\"\n",
    "    \n",
    "    #Aplicar create_dict\n",
    "    create_dict(data, name)\n",
    "    \n",
    "    # Asegurarse de que la carpeta existe\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Crear la ruta completa del archivo\n",
    "    file_path = os.path.join(folder, f'dict_{name}.py')\n",
    "\n",
    "    # Escribir el diccionario en el archivo como código Python\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(f\"# Diccionario generado automáticamente para {name}\\n\")\n",
    "        file.write(f\"dict_df = {column_dict}\\n\")\n",
    "\n",
    "    print(f\"Diccionario guardado exitosamente en: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_dict_as_py(name):\n",
    "#     \"\"\"\n",
    "#     Guarda un diccionario como un archivo .py en la carpeta especificada.\n",
    "    \n",
    "#     Args:\n",
    "#     # - column_dict: El diccionario que se desea guardar.\n",
    "#     - name: El nombre del script (sin extensión .py).\n",
    "#     # - folder: La carpeta donde se guardará el archivo (por defecto: 'Dict').\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Asegurarse de que la carpeta existe\n",
    "#     # os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "#     # Crear la ruta completa del archivo\n",
    "#     file_path = os.path.join('Dict', f'dict_{name}.py')\n",
    "\n",
    "#     # Escribir el diccionario en el archivo como código Python\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(f\"# Diccionario generado automáticamente para {name}\\n\")\n",
    "#         file.write(f\"{name}_df = {name}\\n\")\n",
    "\n",
    "#     print(f\"Diccionario guardado exitosamente en: {file_path}\")\n",
    "    \n",
    "#     return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'target_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m save_dict_as_py(target_dict, target)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'target_dict' is not defined"
     ]
    }
   ],
   "source": [
    "save_dict_as_py(target_dict, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se transformaran los datos inicialmente utilizando One-Hot Encoding para el caso de las columnas categóricas para entrenar un modelo de regresión logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohe = pd.get_dummies(features, drop_first=True)\n",
    "df_ohe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohe_path = os.path.join('Data', '.ipynb_checkpoints', 'df_ohe.csv')\n",
    "\n",
    "df_ohe.to_csv('Data/.ipynb_checkpoints/df_ohe.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificación de etiquetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se  transformaron las columnas categóricas mediante la técnica de codificación de etiquetas para ocuparlas posteriormente en el entrenamiento de modelos de árboles de decisón y bosques aleatorios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder()\n",
    "encoder.fit(df)\n",
    "data_ordinal = encoder.transform(df)\n",
    "data_ordinal = pd.DataFrame(encoder.transform(df), columns=df.columns)\n",
    "\n",
    "print(data_ordinal.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ordinal.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ord = data_ordinal['End_Date']\n",
    "features_ord = data_ordinal.drop('End_Date', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ordinal_path = os.path.join('Data', '.ipynb_checkpoints', 'data_ordinal.csv')\n",
    "target_ord_path = os.path.join('Data', '.ipynb_checkpoints', 'target_ord.csv')\n",
    "features_ord_path = os.path.join('Data', '.ipynb_checkpoints', 'features_ord.csv')\n",
    "\n",
    "data_ordinal.to_csv('Data/.ipynb_checkpoints/data_ordinal.csv', index=False)\n",
    "target_ord.to_csv('Data/.ipynb_checkpoints/target_ord.csv', index=False)\n",
    "features_ord.to_csv('Data/.ipynb_checkpoints/features_ord.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primera división: 40% a temp, 60% para entrenamiento con estratificación\n",
    "features_train, features_temp, target_train, target_temp = train_test_split(\n",
    "    df_ohe, target, test_size=0.4, random_state=12345\n",
    ")\n",
    "\n",
    "# Segunda división: 50% de temp para validación y 50% para prueba con estratificación\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(\n",
    "    features_temp, target_temp, test_size=0.5, random_state=12345\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para bosques aleatorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primera división: 40% de temp, 60% para entrenamiento\n",
    "features_train_ord, features_temp_ord, target_train_ord, target_temp_ord = train_test_split(\n",
    "    features_ord, target_ord, test_size=0.4, random_state=12345\n",
    ")\n",
    "\n",
    "# # Segunda división: 50% de los datos restantes de la división incial para validación y 50% para prueba\n",
    "features_valid_ord, features_test_ord, target_valid_ord, target_test_ord = train_test_split(\n",
    "    features_temp_ord, target_temp_ord, test_size=0.5, random_state=12345\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escalamiento de caractarísticas númericas con StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = ['Monthly_Charges', 'Total_Charges']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "print(features_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_path = os.path.join('Data', '.ipynb_checkpoints', 'features_train.csv')\n",
    "features_valid_path = os.path.join('Data', '.ipynb_checkpoints', 'features_valid.csv')\n",
    "features_test_path = os.path.join('Data', '.ipynb_checkpoints', 'features_test.csv')\n",
    "target_train_path = os.path.join('Data', '.ipynb_checkpoints', 'target_train.csv')\n",
    "target_valid_path = os.path.join('Data', '.ipynb_checkpoints', 'target_valid.csv')\n",
    "target_test_path = os.path.join('Data', 'ipynb_checkpoints', 'target_test.csv')\n",
    "\n",
    "features_train.to_csv(\n",
    "    'Data/.ipynb_checkpoints/features_train.csv', index=False)\n",
    "features_valid.to_csv(\n",
    "    'Data/.ipynb_checkpoints/features_valid.csv', index=False)\n",
    "features_test.to_csv(\n",
    "    'Data/.ipynb_checkpoints/features_test.csv', index=False)\n",
    "target_train.to_csv(\n",
    "    'Data/.ipynb_checkpoints/target_train.csv', index=False)\n",
    "target_valid.to_csv(\n",
    "    'Data/.ipynb_checkpoints/target_valid.csv', index=False)\n",
    "target_test.to_csv(\n",
    "    'Data/.ipynb_checkpoints/target_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para bosques aleatorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_ord = StandardScaler()\n",
    "scaler_ord.fit(features_train_ord[numeric])\n",
    "features_train_ord[numeric] = scaler_ord.transform(features_train_ord[numeric])\n",
    "features_valid_ord[numeric] = scaler_ord.transform(features_valid_ord[numeric])\n",
    "print(features_train_ord.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_ord_path = os.path.join(\n",
    "    'Data', '.ipynb_checkpoints', 'features_train_ord.csv'\n",
    ")\n",
    "features_valid_ord_path = os.path.join(\n",
    "    'Data', '.ipynb_checkpoints', 'features_valid_ord.csv'\n",
    ")\n",
    "features_test_ord_path = os.path.join(\n",
    "    'Data', '.ipynb_checkpoints', 'features_test_ord.csv'\n",
    ")\n",
    "target_train_ord_path = os.path.join(\n",
    "    'Data', '.ipynb_checkpoints', 'target_train_ord.csv'\n",
    ")\n",
    "target_valid_ord_path = os.path.join(\n",
    "    'Data', '.ipynb_checkpoints', 'target_valid_ord.csv'\n",
    ")\n",
    "target_test_ord_path = os.path.join(\n",
    "    'Data', '.ipynb_checkpoints', 'target_test_ord.csv'\n",
    ")\n",
    "\n",
    "\n",
    "features_train_ord.to_csv(\n",
    "    'Data/.ipynb_checkpoints/features_train_ord.csv', \n",
    "    index=False\n",
    ")\n",
    "features_valid_ord.to_csv(\n",
    "    'Data/.ipynb_checkpoints/features_valid_ord.csv', \n",
    "    index=False\n",
    ")\n",
    "features_test_ord.to_csv(\n",
    "    'Data/.ipynb_checkpoints/features_test_ord.csv', \n",
    "    index=False\n",
    ")\n",
    "target_train_ord.to_csv(\n",
    "    'Data/.ipynb_checkpoints/target_train_ord.csv', \n",
    "    index=False\n",
    ")\n",
    "target_valid_ord.to_csv(\n",
    "    'Data/.ipynb_checkpoints/target_valid_ord.csv', \n",
    "    index=False\n",
    ")\n",
    "target_test_ord.to_csv(\n",
    "    'Data/.ipynb_checkpoints/target_test_ord.csv', \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desequilibrio de clases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobar el desequilibrio de las clases en la columna __'End_Date'__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.info()\n",
    "\n",
    "print(target.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = target.value_counts().plot(kind='bar')\n",
    "plt.xticks(rotation=0)\n",
    "plt.xlabel('End_Date')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "for p in ax.containers:\n",
    "    ax.bar_label(p, label_type='edge')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que exite un desiquilibrio de clases en la columna target __'End_Date'__ en un proporción apróximada de 10:1 entre la clase __0__ y __1__ respectivamente. Lo anterior se puede solucionar utiiizando el sobremuestreo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobremuestreo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para regresión logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dividir el conjunto de datos de entrenamiento en observaciones negativas y positivas;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features_train.shape)\n",
    "print(features_valid.shape)\n",
    "print(target_train.shape)\n",
    "print(target_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_zeros = features_train[target_train == 0]\n",
    "features_ones = features_train[target_train == 1]\n",
    "target_zeros = target_train[target_train == 0]\n",
    "target_ones = target_train[target_train == 1]\n",
    "\n",
    "print(features_zeros.shape)\n",
    "print(features_ones.shape)\n",
    "print(target_zeros.shape)\n",
    "print(target_ones.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir función para realizar sobremuestreo\n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345\n",
    "    )\n",
    "\n",
    "    return features_upsampled, target_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = target_upsampled.value_counts().plot(kind='bar')\n",
    "plt.xticks(rotation=0)\n",
    "plt.xlabel('End_Date')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "for p in ax.containers:\n",
    "    ax.bar_label(p, label_type='edge')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_upsampled_path = os.path.join(\n",
    "    'Data', '.ipynb_checkpoints', 'features_upsampled.csv'\n",
    ")\n",
    "target_upsampled_path = os.path.join(\n",
    "    'Data', '.ipynb_checkpoints', 'target_upsampled.csv'\n",
    ")\n",
    "\n",
    "\n",
    "features_upsampled.to_csv(\n",
    "    'Data/.ipynb_checkpoints/features_upsampled.csv', \n",
    "    index=False\n",
    ")\n",
    "target_upsampled.to_csv(\n",
    "    'Data/.ipynb_checkpoints/target_upsampled.csv', \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para bosques aleatorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features_train_ord.shape)\n",
    "print(features_valid_ord.shape)\n",
    "print(target_train_ord.shape)\n",
    "print(target_valid_ord.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_zeros_ord = features_train_ord[target_train_ord == 0]\n",
    "features_ones_ord = features_train_ord[target_train_ord == 1]\n",
    "target_zeros_ord = target_train_ord[target_train_ord == 0]\n",
    "target_ones_ord = target_train_ord[target_train_ord == 1]\n",
    "\n",
    "print(features_zeros_ord.shape)\n",
    "print(features_ones_ord.shape)\n",
    "print(target_zeros_ord.shape)\n",
    "print(target_ones_ord.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_upsampled_ord, target_upsampled_ord = upsample(features_train_ord, target_train_ord, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = target_upsampled_ord.value_counts().plot(kind='bar')\n",
    "plt.xticks(rotation=0)\n",
    "plt.xlabel('End_Date')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "for p in ax.containers:\n",
    "    ax.bar_label(p, label_type='edge')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_upsampled_ord_path = os.path.join(\n",
    "    'Data', '.ipynb_checkpoints', 'features_upsampled_ord.csv' \n",
    ")\n",
    "target_upsampled_ord_path = os.path.join(\n",
    "    'Data', '.ipynb_checkpoints', 'target_upsampled_ord.csv'\n",
    ")\n",
    "\n",
    "features_upsampled_ord.to_csv(\n",
    "    'Data/.ipynb_checkpoints/features_upsampled_ord.csv', \n",
    "    index=False\n",
    ")\n",
    "target_upsampled_ord.to_csv(\n",
    "    'Data/.ipynb_checkpoints/target_upsampled_ord.csv', \n",
    "    index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EnsamblesCatBoost",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
